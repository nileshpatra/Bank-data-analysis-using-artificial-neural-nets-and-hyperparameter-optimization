{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv('/home/nilesh/Desktop/MY FILES/DEEP LEARNING COURSE/2. Artificial_Neural_Networks/Artificial_Neural_Networks/Churn_Modelling.csv' , engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "x = bank.iloc[: , 3:13].values\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bank.iloc[: , 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "labelencode1 = LabelEncoder()\n",
    "labelencode2 = LabelEncoder()\n",
    "x[: , 1] = labelencode1.fit_transform(x[: , 1])\n",
    "x[: , 2] = labelencode2.fit_transform(x[: , 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(categorical_features = [1])\n",
    "x = onehot.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1      2    3     4     5          6    7    8    9          10\n",
      "0     0.0  0.0  619.0  0.0  42.0   2.0       0.00  1.0  1.0  1.0  101348.88\n",
      "1     0.0  1.0  608.0  0.0  41.0   1.0   83807.86  1.0  0.0  1.0  112542.58\n",
      "2     0.0  0.0  502.0  0.0  42.0   8.0  159660.80  3.0  1.0  0.0  113931.57\n",
      "3     0.0  0.0  699.0  0.0  39.0   1.0       0.00  2.0  0.0  0.0   93826.63\n",
      "4     0.0  1.0  850.0  0.0  43.0   2.0  125510.82  1.0  1.0  1.0   79084.10\n",
      "5     0.0  1.0  645.0  1.0  44.0   8.0  113755.78  2.0  1.0  0.0  149756.71\n",
      "6     0.0  0.0  822.0  1.0  50.0   7.0       0.00  2.0  1.0  1.0   10062.80\n",
      "7     1.0  0.0  376.0  0.0  29.0   4.0  115046.74  4.0  1.0  0.0  119346.88\n",
      "8     0.0  0.0  501.0  1.0  44.0   4.0  142051.07  2.0  0.0  1.0   74940.50\n",
      "9     0.0  0.0  684.0  1.0  27.0   2.0  134603.88  1.0  1.0  1.0   71725.73\n",
      "10    0.0  0.0  528.0  1.0  31.0   6.0  102016.72  2.0  0.0  0.0   80181.12\n",
      "11    0.0  1.0  497.0  1.0  24.0   3.0       0.00  2.0  1.0  0.0   76390.01\n",
      "12    0.0  0.0  476.0  0.0  34.0  10.0       0.00  2.0  1.0  0.0   26260.98\n",
      "13    0.0  0.0  549.0  0.0  25.0   5.0       0.00  2.0  0.0  0.0  190857.79\n",
      "14    0.0  1.0  635.0  0.0  35.0   7.0       0.00  2.0  1.0  1.0   65951.65\n",
      "15    1.0  0.0  616.0  1.0  45.0   3.0  143129.41  2.0  0.0  1.0   64327.26\n",
      "16    1.0  0.0  653.0  1.0  58.0   1.0  132602.88  1.0  1.0  0.0    5097.67\n",
      "17    0.0  1.0  549.0  0.0  24.0   9.0       0.00  2.0  1.0  1.0   14406.41\n",
      "18    0.0  1.0  587.0  1.0  45.0   6.0       0.00  1.0  0.0  0.0  158684.81\n",
      "19    0.0  0.0  726.0  0.0  24.0   6.0       0.00  2.0  1.0  1.0   54724.03\n",
      "20    0.0  0.0  732.0  1.0  41.0   8.0       0.00  2.0  1.0  1.0  170886.17\n",
      "21    0.0  1.0  636.0  0.0  32.0   8.0       0.00  2.0  1.0  0.0  138555.46\n",
      "22    0.0  1.0  510.0  0.0  38.0   4.0       0.00  1.0  1.0  0.0  118913.53\n",
      "23    0.0  0.0  669.0  1.0  46.0   3.0       0.00  2.0  0.0  1.0    8487.75\n",
      "24    0.0  0.0  846.0  0.0  38.0   5.0       0.00  1.0  1.0  1.0  187616.16\n",
      "25    0.0  0.0  577.0  1.0  25.0   3.0       0.00  2.0  0.0  1.0  124508.29\n",
      "26    1.0  0.0  756.0  1.0  36.0   2.0  136815.64  1.0  1.0  1.0  170041.95\n",
      "27    0.0  0.0  571.0  1.0  44.0   9.0       0.00  2.0  0.0  0.0   38433.35\n",
      "28    1.0  0.0  574.0  0.0  43.0   3.0  141349.43  1.0  1.0  1.0  100187.43\n",
      "29    0.0  0.0  411.0  1.0  29.0   0.0   59697.17  2.0  1.0  1.0   53483.21\n",
      "...   ...  ...    ...  ...   ...   ...        ...  ...  ...  ...        ...\n",
      "9970  0.0  0.0  518.0  1.0  42.0   7.0  151027.05  2.0  1.0  0.0  119377.36\n",
      "9971  0.0  0.0  833.0  0.0  34.0   3.0  144751.81  1.0  0.0  0.0  166472.81\n",
      "9972  0.0  0.0  758.0  1.0  26.0   4.0  155739.76  1.0  1.0  0.0  171552.02\n",
      "9973  0.0  0.0  611.0  1.0  27.0   7.0       0.00  2.0  1.0  1.0  157474.10\n",
      "9974  0.0  0.0  583.0  1.0  33.0   7.0  122531.86  1.0  1.0  0.0   13549.24\n",
      "9975  1.0  0.0  610.0  1.0  50.0   1.0  113957.01  2.0  1.0  0.0  196526.55\n",
      "9976  0.0  0.0  637.0  0.0  33.0   7.0  103377.81  1.0  1.0  0.0   84419.78\n",
      "9977  0.0  0.0  683.0  0.0  32.0   9.0       0.00  2.0  1.0  1.0   24991.92\n",
      "9978  0.0  0.0  774.0  1.0  40.0   9.0   93017.47  2.0  1.0  0.0  191608.97\n",
      "9979  0.0  0.0  677.0  0.0  58.0   1.0   90022.85  1.0  0.0  1.0    2988.28\n",
      "9980  0.0  1.0  741.0  1.0  35.0   6.0   74371.49  1.0  0.0  0.0   99595.67\n",
      "9981  1.0  0.0  498.0  1.0  42.0   3.0  152039.70  1.0  1.0  1.0   53445.17\n",
      "9982  1.0  0.0  655.0  0.0  46.0   7.0  137145.12  1.0  1.0  0.0  115146.40\n",
      "9983  0.0  0.0  613.0  1.0  40.0   4.0       0.00  1.0  0.0  0.0  151325.24\n",
      "9984  1.0  0.0  602.0  1.0  35.0   7.0   90602.42  2.0  1.0  1.0   51695.41\n",
      "9985  0.0  0.0  659.0  1.0  36.0   6.0  123841.49  2.0  1.0  0.0   96833.00\n",
      "9986  1.0  0.0  673.0  1.0  47.0   1.0  183579.54  2.0  0.0  1.0   34047.54\n",
      "9987  0.0  1.0  606.0  1.0  30.0   8.0  180307.73  2.0  1.0  1.0    1914.41\n",
      "9988  0.0  0.0  775.0  1.0  30.0   4.0       0.00  2.0  1.0  0.0   49337.84\n",
      "9989  0.0  1.0  841.0  1.0  28.0   4.0       0.00  2.0  1.0  1.0  179436.60\n",
      "9990  1.0  0.0  714.0  1.0  33.0   3.0   35016.60  1.0  1.0  0.0   53667.08\n",
      "9991  0.0  0.0  597.0  0.0  53.0   4.0   88381.21  1.0  1.0  0.0   69384.71\n",
      "9992  0.0  1.0  726.0  1.0  36.0   2.0       0.00  1.0  1.0  0.0  195192.40\n",
      "9993  0.0  0.0  644.0  1.0  28.0   7.0  155060.41  1.0  1.0  0.0   29179.52\n",
      "9994  0.0  0.0  800.0  0.0  29.0   2.0       0.00  2.0  0.0  0.0  167773.55\n",
      "9995  0.0  0.0  771.0  1.0  39.0   5.0       0.00  2.0  1.0  0.0   96270.64\n",
      "9996  0.0  0.0  516.0  1.0  35.0  10.0   57369.61  1.0  1.0  1.0  101699.77\n",
      "9997  0.0  0.0  709.0  0.0  36.0   7.0       0.00  1.0  0.0  1.0   42085.58\n",
      "9998  1.0  0.0  772.0  1.0  42.0   3.0   75075.31  2.0  1.0  0.0   92888.52\n",
      "9999  0.0  0.0  792.0  0.0  28.0   4.0  130142.79  1.0  1.0  0.0   38190.78\n",
      "\n",
      "[10000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain , xtest , ytrain , ytest = train_test_split(x, y , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "xtrain = scl.fit_transform(xtrain)\n",
    "xtest = scl.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu' , input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(output_dim = 1 , init = 'uniform' , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(xtrain , ytrain , batch_size = 10 , nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = classifier.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ypred)):\n",
    "    if ypred[i]>=0.5:\n",
    "        ypred[i]=1\n",
    "    else:\n",
    "        ypred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ytest ,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.ravel(ypred) == ytest).sum())/len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = np.array([[0 , 0 , 600 , 1 , 40 , 3 , 60000 , 2, 1 ,1 , 50000]])\n",
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = scl.transform(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = classifier.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu' , input_dim = 11))    \n",
    "    classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu'))    \n",
    "    classifier.add(Dense(output_dim = 1 , init = 'uniform' , activation = 'sigmoid'))    \n",
    "    classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])  \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_clf , batch_size = 10  ,nb_epoch = 100)\n",
    "accuracies = cross_val_score(estimator = classifier , X = xtrain , y = ytrain , cv = 10 , n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean , variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding overfitting using droupout regularization\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu' , input_dim = 11))    \n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu' , input_dim = 11))    \n",
    "    classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu'))    \n",
    "    classifier.add(Dense(output_dim = 1 , init = 'uniform' , activation = 'sigmoid'))    \n",
    "    classifier.compile(optimizer = optimizer , loss = 'binary_crossentropy' , metrics = ['accuracy'])  \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = build_clf)\n",
    "parameters = {'batch_size' : [25 , 35] , 'nb_epoch' : [100 , 350] , 'optimizer' : ['adam' , 'rmsprop']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/nilesh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 0s 49us/step - loss: 0.5554 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 0s 56us/step - loss: 0.5498 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 0s 55us/step - loss: 0.5549 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 0s 64us/step - loss: 0.5663 - acc: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 72us/step - loss: 0.5759 - acc: 0.7889\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 0s 65us/step - loss: 0.5675 - acc: 0.7915\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5631 - acc: 0.7910\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.5658 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.5512 - acc: 0.7947\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.5864 - acc: 0.7893\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.5792 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.5751 - acc: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 115us/step - loss: 0.6215 - acc: 0.7933\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 124us/step - loss: 0.5607 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 127us/step - loss: 0.5684 - acc: 0.7906\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 136us/step - loss: 0.6004 - acc: 0.7904\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 141us/step - loss: 0.5728 - acc: 0.7917\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 142us/step - loss: 0.5714 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 156us/step - loss: 0.5780 - acc: 0.7946\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 157us/step - loss: 0.5717 - acc: 0.7908\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 174us/step - loss: 0.5848 - acc: 0.7938\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 179us/step - loss: 0.5544 - acc: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 187us/step - loss: 0.5583 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.5517 - acc: 0.7940\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 1s 205us/step - loss: 0.5631 - acc: 0.7894\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 219us/step - loss: 0.5431 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 232us/step - loss: 0.5634 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 239us/step - loss: 0.5411 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 249us/step - loss: 0.5625 - acc: 0.7954\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 268us/step - loss: 0.5573 - acc: 0.7908\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 263us/step - loss: 0.5680 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 272us/step - loss: 0.5611 - acc: 0.7922\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 281us/step - loss: 0.6058 - acc: 0.7911\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 291us/step - loss: 0.5961 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 306us/step - loss: 0.5719 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 310us/step - loss: 0.5812 - acc: 0.7924\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 319us/step - loss: 0.6227 - acc: 0.7901\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 328us/step - loss: 0.5828 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 2s 341us/step - loss: 0.5744 - acc: 0.7958\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.5667 - acc: 0.7914\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 361us/step - loss: 0.6042 - acc: 0.7911\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 370us/step - loss: 0.6174 - acc: 0.7904\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 389us/step - loss: 0.6040 - acc: 0.7917\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 400us/step - loss: 0.6282 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 403us/step - loss: 0.5932 - acc: 0.7906\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 411us/step - loss: 0.6354 - acc: 0.7910\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 434us/step - loss: 0.5873 - acc: 0.7915\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 465us/step - loss: 0.5936 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 553us/step - loss: 0.6097 - acc: 0.7938\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 3s 484us/step - loss: 0.6058 - acc: 0.7892\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 487us/step - loss: 0.6215 - acc: 0.7932\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 500us/step - loss: 0.6316 - acc: 0.7910\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 505us/step - loss: 0.6233 - acc: 0.7928\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 532us/step - loss: 0.6194 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 526us/step - loss: 0.6006 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 551us/step - loss: 0.6417 - acc: 0.7894\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 553us/step - loss: 0.5932 - acc: 0.7921\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 560us/step - loss: 0.6059 - acc: 0.7942\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 581us/step - loss: 0.6159 - acc: 0.7936\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 675us/step - loss: 0.6048 - acc: 0.7914\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 711us/step - loss: 0.5822 - acc: 0.7949\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 4s 615us/step - loss: 0.5982 - acc: 0.7900\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 747us/step - loss: 0.6443 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 772us/step - loss: 0.6047 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 666us/step - loss: 0.6067 - acc: 0.7899\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 670us/step - loss: 0.6027 - acc: 0.7919\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 807us/step - loss: 0.5991 - acc: 0.7917\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 770us/step - loss: 0.6046 - acc: 0.7929\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.5938 - acc: 0.7943\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.6116 - acc: 0.7910\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 845us/step - loss: 0.6360 - acc: 0.7931\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 733us/step - loss: 0.6332 - acc: 0.7907\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 6s 814us/step - loss: 0.6190 - acc: 0.7917\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 5s 764us/step - loss: 0.5974 - acc: 0.7944\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.5958 - acc: 0.7913\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.5903 - acc: 0.7926\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.6112 - acc: 0.7894\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 7s 1ms/step - loss: 0.6275 - acc: 0.7935\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 8s 1ms/step - loss: 0.6017 - acc: 0.7951\n",
      "Epoch 1/1\n",
      "7200/7200 [==============================] - 9s 1ms/step - loss: 0.6041 - acc: 0.7908\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5375 - acc: 0.7927\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier , param_grid = parameters , scoring = 'accuracy' , cv = 10)\n",
    "search = grid_search.fit(xtrain , ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 25, 'nb_epoch': 100, 'optimizer': 'adam'} 0.793375\n"
     ]
    }
   ],
   "source": [
    "best_parameters = search.best_params_\n",
    "best_accuracy = search.best_score_\n",
    "print(best_parameters , best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
